{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Building3D': {'root_dir': 'E:\\\\Building3D\\\\clear data\\\\Entry-level', 'num_points': 2560, 'use_color': True, 'use_intensity': True, 'normalize': True, 'augment': True}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from datasets import build_dataset\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "def cfg_from_yaml_file(cfg_file):\n",
    "    with open(cfg_file, 'r') as f:\n",
    "        try:\n",
    "            new_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        except:\n",
    "            new_config = yaml.load(f)\n",
    "\n",
    "    cfg = EasyDict(new_config)\n",
    "    return cfg\n",
    "\n",
    "dataset_config = cfg_from_yaml_file('dataset_config.yaml')\n",
    "print(dataset_config)\n",
    "\n",
    "building3D_dataset = build_dataset(dataset_config.Building3D)\n",
    "# print(dir(building3D_dataset['train']))\n",
    "# print(building3D_dataset[\"test\"].wireframe_files)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T21:17:47.387940Z",
     "end_time": "2023-08-12T21:17:47.445181Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point_clouds  torch.Size([3, 2560, 8])\n",
      "wf_vertices torch.Size([3, 16, 3])\n",
      "wf_edges torch.Size([3, 22, 2])\n",
      "centroid torch.Size([3, 3])\n",
      "max_distance torch.Size([3])\n",
      "scan_idx torch.Size([3])\n",
      "tensor([[[ 4.,  6.],\n",
      "         [12., 13.],\n",
      "         [ 5.,  7.],\n",
      "         [ 0.,  2.],\n",
      "         [ 8.,  9.],\n",
      "         [ 0.,  8.],\n",
      "         [ 1.,  3.],\n",
      "         [13., 14.],\n",
      "         [ 7., 10.],\n",
      "         [ 4.,  5.],\n",
      "         [ 3.,  9.],\n",
      "         [12., 15.],\n",
      "         [14., 15.],\n",
      "         [ 8., 14.],\n",
      "         [ 1.,  2.],\n",
      "         [10., 11.],\n",
      "         [ 6.,  7.],\n",
      "         [ 5., 11.],\n",
      "         [ 0.,  3.],\n",
      "         [10., 13.],\n",
      "         [ 9., 15.],\n",
      "         [11., 12.]],\n",
      "\n",
      "        [[ 1.,  2.],\n",
      "         [10., 11.],\n",
      "         [ 1.,  5.],\n",
      "         [ 2., 10.],\n",
      "         [ 0.,  3.],\n",
      "         [ 0.,  6.],\n",
      "         [ 2.,  3.],\n",
      "         [ 6.,  7.],\n",
      "         [ 4.,  5.],\n",
      "         [ 4.,  7.],\n",
      "         [ 8.,  9.],\n",
      "         [ 1.,  9.],\n",
      "         [ 8., 11.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.]],\n",
      "\n",
      "        [[ 0.,  1.],\n",
      "         [ 1.,  2.],\n",
      "         [ 0.,  3.],\n",
      "         [ 1.,  4.],\n",
      "         [ 2.,  3.],\n",
      "         [ 4.,  5.],\n",
      "         [ 0.,  5.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.],\n",
      "         [-1., -1.]]])\n",
      "tensor([[5.3680e+05, 6.5848e+06, 2.3519e+01],\n",
      "        [5.3693e+05, 6.5825e+06, 5.6819e+01],\n",
      "        [5.3354e+05, 6.5906e+06, 1.3799e+01]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(building3D_dataset['train'], batch_size=3, shuffle=True, drop_last=True, collate_fn=building3D_dataset['train'].collate_batch)\n",
    "for batch in train_loader:\n",
    "\n",
    "    print('point_clouds ', batch['point_clouds'].shape)\n",
    "    print('wf_vertices', batch['wf_vertices'].shape)\n",
    "    print('wf_edges', batch['wf_edges'].shape)\n",
    "    print('centroid', batch['centroid'].shape)\n",
    "    print('max_distance', batch['max_distance'].shape)\n",
    "    print('scan_idx', batch['scan_idx'].shape)\n",
    "    print(batch['wf_edges'])\n",
    "    print(batch['centroid'])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T21:21:26.447737Z",
     "end_time": "2023-08-12T21:21:27.216686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T21:15:10.373135Z",
     "end_time": "2023-08-12T21:15:10.414238Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}